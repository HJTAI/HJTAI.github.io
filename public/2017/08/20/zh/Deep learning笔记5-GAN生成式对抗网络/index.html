

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/HJT.png">
  <link rel="icon" href="/img/HJT.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="H.J.T.">
  <meta name="keywords" content="">
  
    <meta name="description" content="1. 生成式对抗网络（GAN） GAN（Generative Adversarial Network）的思想：生成器和鉴别器两个网络彼此博弈。 ● 生成器的目标是生成一个对象，并使其看起来和真的一样。 ● 鉴别器的目标就是找到生成出的结果和真实图像之间的差异。   GAN   内容部分来自：はじめてのGAN 訓練データを学習し、それらのデータと似たような新しいデータを生成するモデルのことを生成モデ">
<meta property="og:type" content="article">
<meta property="og:title" content="Deep learning笔记5-GAN生成式对抗网络">
<meta property="og:url" content="https://hjtai.github.io/2017/08/20/zh/Deep%20learning%E7%AC%94%E8%AE%B05-GAN%E7%94%9F%E6%88%90%E5%BC%8F%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/index.html">
<meta property="og:site_name" content="H.J.T. Home">
<meta property="og:description" content="1. 生成式对抗网络（GAN） GAN（Generative Adversarial Network）的思想：生成器和鉴别器两个网络彼此博弈。 ● 生成器的目标是生成一个对象，并使其看起来和真的一样。 ● 鉴别器的目标就是找到生成出的结果和真实图像之间的差异。   GAN   内容部分来自：はじめてのGAN 訓練データを学習し、それらのデータと似たような新しいデータを生成するモデルのことを生成モデ">
<meta property="og:locale">
<meta property="og:image" content="https://hjtai.github.io/image/DL/5/1-1.jpg">
<meta property="og:image" content="https://hjtai.github.io/image/DL/5/1-2.jpg">
<meta property="og:image" content="https://hjtai.github.io/image/DL/5/1-3.png">
<meta property="og:image" content="https://hjtai.github.io/image/DL/5/1-4.png">
<meta property="og:image" content="https://hjtai.github.io/image/DL/5/1-5.png">
<meta property="og:image" content="https://hjtai.github.io/image/DL/5/2-1.png">
<meta property="og:image" content="https://hjtai.github.io/image/DL/5/2-2.png">
<meta property="article:published_time" content="2017-08-20T09:18:56.000Z">
<meta property="article:modified_time" content="2022-08-08T11:19:47.075Z">
<meta property="article:author" content="H.J.T.">
<meta property="article:tag" content="Deep Learning">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://hjtai.github.io/image/DL/5/1-1.jpg">
  
  
  
  <title>Deep learning笔记5-GAN生成式对抗网络 - H.J.T. Home</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"hjtai.github.io","root":"/","version":"1.9.2","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>H.J.T. Home</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                Home
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                Archives
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                Categories
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                Tags
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                About
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Deep learning笔记5-GAN生成式对抗网络"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2017-08-20 18:18" pubdate>
          August 20, 2017 pm
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          8.4k words
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          70 mins
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Deep learning笔记5-GAN生成式对抗网络</h1>
            
            
              <div class="markdown-body">
                
                <h3 id="生成式对抗网络gan">1. 生成式对抗网络（GAN）</h3>
<p>GAN（Generative Adversarial Network）的思想：生成器和鉴别器两个网络彼此博弈。</p>
<p>● 生成器的目标是生成一个对象，并使其看起来和真的一样。</p>
<p>● 鉴别器的目标就是找到生成出的结果和真实图像之间的差异。</p>
<hr />
<figure>
<img src="/image/DL/5/1-1.jpg" srcset="/img/loading.gif" lazyload alt="GAN" /><figcaption aria-hidden="true">GAN</figcaption>
</figure>
<hr />
<p>内容部分来自：<a target="_blank" rel="noopener" href="https://elix-tech.github.io/ja/2017/02/06/gan.html" title="Title">はじめてのGAN</a></p>
<p>訓練データを学習し、それらのデータと似たような新しいデータを生成するモデルのことを生成モデルと呼びます。別の言い方をすると、訓練データの分布と生成データの分布が一致するように学習していくようなモデルです。</p>
<p>GANではgeneratorとdiscriminatorという２つのネットワークが登場します。Generatorは訓練データと同じようなデータを生成しようとします。一方、discriminatorはデータが訓練データから来たものか、それとも生成モデルから来たものかを識別します。</p>
<hr />
<figure>
<img src="/image/DL/5/1-2.jpg" srcset="/img/loading.gif" lazyload alt="GAN" /><figcaption aria-hidden="true">GAN</figcaption>
</figure>
<hr />
<p>如上图所示，生成对抗网络会训练并更新判别分布，更新判别器后就能将数据真实分布从生成分布中判别出来。经过若干次训练后，如果 G 和 D 有足够的复杂度，那么它们就会到达一个均衡点。这个时候生成器的概率密度函数等于真实数据的概率密度函数，也即生成的数据和真实数据是一样的。在均衡点上 D 和 G 都不能得到进一步提升，并且判别器无法判断数据到底是来自真实样本还是伪造的数据，即 D（x）= 1/2。</p>
<p>GAN学习的表征可用于多种应用，包括图像合成、语义图像编辑、风格迁移、图像超分辨率技术和分类。</p>
<p>eg. ベッドルームの画像のデータセットを使って学習した結果です。一見本物と見間違ってしまいそうなレベルの画像を生成できていることが分かります。</p>
<hr />
<figure>
<img src="/image/DL/5/1-3.png" srcset="/img/loading.gif" lazyload alt="GAN" /><figcaption aria-hidden="true">GAN</figcaption>
</figure>
<hr />
<p>eg. Word2Vecという単語ベクトルで「王様」-「男」+「女」=「女王」という演算ができることは有名ですが、GANにおける入力であるzzベクトルを使っても同様の演算を行うことができます。下の例では、「サングラスをかけた男」-「男」+「女」=「サングラスをかけた女」という演算を行っています。</p>
<hr />
<figure>
<img src="/image/DL/5/1-4.png" srcset="/img/loading.gif" lazyload alt="GAN" /><figcaption aria-hidden="true">GAN</figcaption>
</figure>
<hr />
<p>GAN的类别 - 内容来自：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/30346797" title="Title">生成对抗网络综述：从架构到训练技巧</a></p>
<h4 id="全连接-gan">1.1. 全连接 GAN</h4>
<p>首个 GAN 架构在生成器与鉴别器上皆使用全连接神经网络。这种架构类型被应用于相对简单的图像数据库，即 MNIST（手写数字）、CIFAR-10（自然图像）和多伦多人脸数据集（TFD）。</p>
<h4 id="卷积-gan">1.2. 卷积 GAN</h4>
<p>● LAPGAN拉普拉斯金字塔形对抗网络（Laplacian pyramid GAN）</p>
<p>真值图像本身被分解成拉普拉斯金字塔（Laplacian pyramid），并且条件性卷积 GAN 被训练在给定上一层的情况下生成每一层。</p>
<p>● DCGAN（Deep Convolutional GAN）</p>
<hr />
<figure>
<img src="/image/DL/5/1-5.png" srcset="/img/loading.gif" lazyload alt="GAN" /><figcaption aria-hidden="true">GAN</figcaption>
</figure>
<hr />
<p>DCGAN允许训练一对深度卷积生成器和判别器网络。在训练中使用带步长的卷积（strided convolution）和小步长卷积（fractionally-strided convolution），并在训练中学习空间下采样和上采样算子。</p>
<h4 id="条件-gan">1.3. 条件 GAN</h4>
<p>通过将生成器和判别器改造成条件类（class-conditional）而将（2D）GAN 框架扩展成条件设置。条件 GNN 的优势在于可以对多形式的数据生成提供更好的表征。条件 GAN 和 InfoGAN[16] 是平行的，它可以将噪声源分解为不可压缩源和一个「隐编码」（latent code），并可以通过最大化隐编码和生成器之间的交互信息而发现变化的隐藏因子。这个隐编码可用于在完全无监督的数据中发现目标类，即使这个隐编码是不明确的。由 InfoGAN 学到的表征看起来像是具备语义特征的，可以处理图貌中的复杂纠缠因素（包括姿势变化、光照和面部图像的情绪内容）。</p>
<h4 id="gan-推断模型">1.4. GAN 推断模型</h4>
<p>GAN 的初始形式无法将给定的输入 x 映射为隐空间中的向量（在 GAN 的文献中，这通常被称为一种推断机制）。人们提出了几种反转预训练 GAN 的生成器的技术，比如各自独立提出的对抗性学习推断（Adversarially Learned Inference，ALI）和双向 GAN（Bidirectional GANs），它们能提供简单而有效的扩展，通过加入一个推断网络，使判别器共同测试数据空间和隐空间。</p>
<p>这种形式下的生成器由两个网络组成：即编码器（推断网络）和解码器。它们同时被训练用于欺骗判别器。而判别器将接收到一个向量对（x,z），并决定其是否包含一个真实图像以及其编码，或者一个生成的图像样本以及相关的生成器的隐空间输入。</p>
<h4 id="aae-对抗自编码器">1.5. AAE 对抗自编码器</h4>
<p>自编码器是由编码器和解码器组成的网络，学习将数据映射到内部隐表征中，再映射出来，即从数据空间中学习将图像（或其它）通过编码映射到隐空间中，再通过解码从隐空间映射回数据空间。这两个映射形成了一种重构运算，而这两个映射将被训练直到重构图像尽可能的接近初始图像。</p>
<h3 id="生成式对抗网络的训练gan-training">2. 生成式对抗网络的训练（GAN Training）</h3>
<p>生成对抗网络（GAN）提供了一种不需要大量标注训练数据就能学习深度表征的方式。它们通过反向传播算法分别更新两个网络以执行竞争性学习而达到训练目的。</p>
<h4 id="训练">2.1. 训练</h4>
<p>训练的代价由一个价值函数 V(G,D) 评估，其包含了生成器和判别器的参数。</p>
<p>训练过程可表示如下：</p>
<hr />
<figure>
<img src="/image/DL/5/2-1.png" srcset="/img/loading.gif" lazyload alt="GAN" /><figcaption aria-hidden="true">GAN</figcaption>
</figure>
<hr />
<p>训练过程中，其中一个模型的参数被更新，同时另一个模型的参数固定不变。</p>
<p>算法描述：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1406.2661" title="Title">Goodfellow et al. (2014)</a> より引用</p>
<hr />
<figure>
<img src="/image/DL/5/2-2.png" srcset="/img/loading.gif" lazyload alt="GAN" /><figcaption aria-hidden="true">GAN</figcaption>
</figure>
<hr />
<p>推荐阅读 - <a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650731540&amp;idx=1&amp;sn=193457603fe11b89f3d298ac1799b9fd&amp;chksm=871b306ab06cb97c502af9552657b8e73f1f5286bc4cc71b021f64604fd53dae3f026bc9ac69&amp;scene=21#wechat_redirect" title="Title">机器之心GitHub项目：GAN完整理论推导与实现</a></p>
<p>推荐阅读 - <a target="_blank" rel="noopener" href="https://elix-tech.github.io/ja/2017/02/06/gan.html" title="Title">はじめてのGAN</a></p>
<h4 id="训练技巧">2.2. 训练技巧</h4>
<p>用于图像生成的 GAN 训练的第一个重大改进是 Radford et al.提出的 DCGAN 架构。具体到训练中，研究者推荐在两种网络中使用批量归一化，以稳定深层模型中的训练。另一个建议是最小化用于提升深层模型训练可行性的全连接层的数量。最后，Radford et al.认为在判别器中间层使用leaky ReLU激活函数的性能优于使用常规的 ReLU 函数。</p>
<p>● 特征匹配稍稍改变生成器的目标，以增加可获取的信息量。</p>
<p>● 小批量判别（mini-batch discrimination）向判别器额外添加输入，该特征对小批量中的给定样本和其他样本的距离进行编码，防止模式崩溃（mode collapse），因为判别器能够轻易判断生成器是否生成同样的输出。</p>
<p>● 启发式平均（heuristic averaging），如果网络参数偏离之前值的运行平均值，则会受到惩罚，这有助于收敛到平衡态。</p>
<p>● 虚拟批量归一化（virtual batch normalization），可减少小批量内样本对其他样本的依赖性，方法是使用训练开始就确定的固定参考小批量（reference mini-batch）样本计算归一化的批量统计（batch statistics）。</p>
<p>● 单边标签平滑（one-sided label smoothing）将判别器的目标从 1 替换为 0.9，使判别器的分类边界变得平滑，从而阻止判别器过于自信，为生成器提供较差的梯度。</p>
<h3 id="基于tensorflow的keras实现keras">3. 基于TensorFlow的Keras实现（Keras）</h3>
<p>内容来自：<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650731540&amp;idx=1&amp;sn=193457603fe11b89f3d298ac1799b9fd&amp;chksm=871b306ab06cb97c502af9552657b8e73f1f5286bc4cc71b021f64604fd53dae3f026bc9ac69&amp;scene=21#wechat_redirect" title="Title">机器之心GitHub项目：GAN完整理论推导与实现</a></p>
<p>详见代码：<a target="_blank" rel="noopener" href="https://github.com/jiqizhixin/ML-Tutorial-Experiment" title="Title">机器之心 - GAN GitHub实现地址</a></p>
<h4 id="生成模型">● 生成模型</h4>
<p>首先需要定义一个生成器 G，该生成器需要将输入的随机噪声变换为图像。以下是定义的生成模型，该模型首先输入有 100 个元素的向量，该向量随机生成于某分布。随后利用两个全连接层接连将该输入向量扩展到 1024 维和 128<em>7</em>7 维，后面就开始将全连接层所产生的一维张量重新塑造成二维张量，即 MNIST 中的灰度图。我们注意到该模型采用的激活函数为 tanh，所以也尝试过将其转换为 relu 函数，但发现生成模型如果转化为 relu 函数，那么它的输出就会成为一片灰色。</p>
<p>由全连接传递的数据会经过几个上采样层和卷积层，我们注意到最后一个卷积层所采用的卷积核为 1，所以经过最后卷积层所生成的图像是一张二维灰度图像。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">generator_model</span>():<br>    <span class="hljs-comment">#下面搭建生成器的架构，首先导入序贯模型（sequential），即多个网络层的线性堆叠</span><br>    model = Sequential()<br>    <span class="hljs-comment">#添加一个全连接层，输入为100维向量，输出为1024维</span><br>    model.add(Dense(input_dim=<span class="hljs-number">100</span>, output_dim=<span class="hljs-number">1024</span>))<br>    <span class="hljs-comment">#添加一个激活函数tanh</span><br>    model.add(Activation(<span class="hljs-string">&#x27;tanh&#x27;</span>))<br>    <span class="hljs-comment">#添加一个全连接层，输出为128×7×7维度</span><br>    model.add(Dense(<span class="hljs-number">128</span>*<span class="hljs-number">7</span>*<span class="hljs-number">7</span>))<br>    <span class="hljs-comment">#添加一个批量归一化层，该层在每个batch上将前一层的激活值重新规范化，即使得其输出数据的均值接近0，其标准差接近1</span><br>    model.add(BatchNormalization())<br>    model.add(Activation(<span class="hljs-string">&#x27;tanh&#x27;</span>))<br>    <span class="hljs-comment">#Reshape层用来将输入shape转换为特定的shape，将含有128*7*7个元素的向量转化为7×7×128张量</span><br>    model.add(Reshape((<span class="hljs-number">7</span>, <span class="hljs-number">7</span>, <span class="hljs-number">128</span>), input_shape=(<span class="hljs-number">128</span>*<span class="hljs-number">7</span>*<span class="hljs-number">7</span>,)))<br>    <span class="hljs-comment">#2维上采样层，即将数据的行和列分别重复2次</span><br>    model.add(UpSampling2D(size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)))<br>    <span class="hljs-comment">#添加一个2维卷积层，卷积核大小为5×5，激活函数为tanh，共64个卷积核，并采用padding以保持图像尺寸不变</span><br>    model.add(Conv2D(<span class="hljs-number">64</span>, (<span class="hljs-number">5</span>, <span class="hljs-number">5</span>), padding=<span class="hljs-string">&#x27;same&#x27;</span>))<br>    model.add(Activation(<span class="hljs-string">&#x27;tanh&#x27;</span>))<br>    model.add(UpSampling2D(size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)))<br>    <span class="hljs-comment">#卷积核设为1即输出图像的维度</span><br>    model.add(Conv2D(<span class="hljs-number">1</span>, (<span class="hljs-number">5</span>, <span class="hljs-number">5</span>), padding=<span class="hljs-string">&#x27;same&#x27;</span>))<br>    model.add(Activation(<span class="hljs-string">&#x27;tanh&#x27;</span>))<br>    <span class="hljs-keyword">return</span> model<br></code></pre></td></tr></table></figure>
<h4 id="判别模型">● 判别模型</h4>
<p>判别模型相对来说就是比较传统的图像识别模型，前面我们可以按照经典的方法采用几个卷积层与最大池化层，而后再展开为一维张量并采用几个全连接层作为架构。我们尝试了将 tanh 激活函数改为 relu 激活函数，在前两个 epoch 基本上没有什么明显的变化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">discriminator_model</span>():<br>    <span class="hljs-comment">#下面搭建判别器架构，同样采用序贯模型</span><br>    model = Sequential()<br>    <br>    <span class="hljs-comment">#添加2维卷积层，卷积核大小为5×5，激活函数为tanh，输入shape在‘channels_first’模式下为（samples,channels，rows，cols）</span><br>    <span class="hljs-comment">#在‘channels_last’模式下为（samples,rows,cols,channels），输出为64维</span><br>    model.add(<br>            Conv2D(<span class="hljs-number">64</span>, (<span class="hljs-number">5</span>, <span class="hljs-number">5</span>),<br>            padding=<span class="hljs-string">&#x27;same&#x27;</span>,<br>            input_shape=(<span class="hljs-number">28</span>, <span class="hljs-number">28</span>, <span class="hljs-number">1</span>))<br>            )<br>    model.add(Activation(<span class="hljs-string">&#x27;tanh&#x27;</span>))<br>    <span class="hljs-comment">#为空域信号施加最大值池化，pool_size取（2，2）代表使图片在两个维度上均变为原长的一半</span><br>    model.add(MaxPooling2D(pool_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)))<br>    model.add(Conv2D(<span class="hljs-number">128</span>, (<span class="hljs-number">5</span>, <span class="hljs-number">5</span>)))<br>    model.add(Activation(<span class="hljs-string">&#x27;tanh&#x27;</span>))<br>    model.add(MaxPooling2D(pool_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)))<br>    <span class="hljs-comment">#Flatten层把多维输入一维化，常用在从卷积层到全连接层的过渡</span><br>    model.add(Flatten())<br>    model.add(Dense(<span class="hljs-number">1024</span>))<br>    model.add(Activation(<span class="hljs-string">&#x27;tanh&#x27;</span>))<br>    <span class="hljs-comment">#一个结点进行二值分类，并采用sigmoid函数的输出作为概念</span><br>    model.add(Dense(<span class="hljs-number">1</span>))<br>    model.add(Activation(<span class="hljs-string">&#x27;sigmoid&#x27;</span>))<br>    <span class="hljs-keyword">return</span> model<br></code></pre></td></tr></table></figure>
<h4 id="拼接">● 拼接</h4>
<p>前面定义的是可生成图像的模型 G，而我们在训练生成模型时，需要固定判别模型 D 以极小化价值函数而寻求更好的生成模型，这就意味着我们需要将生成模型与判别模型拼接在一起，并固定 D 的权重以训练 G 的权重。下面就定义了这一过程，我们先添加前面定义的生成模型，再将定义的判别模型拼接在生成模型下方，并且我们将判别模型设置为不可训练。因此，训练这个组合模型才能真正更新生成模型的参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">generator_containing_discriminator</span>(<span class="hljs-params">g, d</span>):<br>    <span class="hljs-comment">#将前面定义的生成器架构和判别器架构组拼接成一个大的神经网络，用于判别生成的图片</span><br>    model = Sequential()<br>    <span class="hljs-comment">#先添加生成器架构，再令d不可训练，即固定d</span><br>    <span class="hljs-comment">#因此在给定d的情况下训练生成器，即通过将生成的结果投入到判别器进行辨别而优化生成器</span><br>    model.add(g)<br>    d.trainable = <span class="hljs-literal">False</span><br>    model.add(d)<br>    <span class="hljs-keyword">return</span> model<br></code></pre></td></tr></table></figure>
<h4 id="训练-1">● 训练</h4>
<p>以下训练过程可简述为：</p>
<ul>
<li>加载 MNIST 数据</li>
<li>将数据分割为训练与测试集，并赋值给变量</li>
<li>设置训练模型的超参数</li>
<li>编译模型的训练过程</li>
<li>在每一次迭代内，抽取生成图像与真实图像，并打上标注</li>
<li>随后将数据投入到判别模型中，并进行训练与计算损失</li>
<li>固定判别模型，训练生成模型并计算损失，结束这一次迭代</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">BATCH_SIZE</span>):<br>    <br>    <span class="hljs-comment"># 国内好像不能直接导入数据集，我们试了几次都不行，后来将数据集下载到本地&#x27;~/.keras/datasets/&#x27;，也就是当前目录（我的是用户文件夹下）下的.keras文件夹中。</span><br>    <span class="hljs-comment">#下载的地址为：https://s3.amazonaws.com/img-datasets/mnist.npz</span><br>    (X_train, y_train), (X_test, y_test) = mnist.load_data()<br>    <span class="hljs-comment">#iamge_data_format选择&quot;channels_last&quot;或&quot;channels_first&quot;，该选项指定了Keras将要使用的维度顺序。</span><br>    <span class="hljs-comment">#&quot;channels_first&quot;假定2D数据的维度顺序为(channels, rows, cols)，3D数据的维度顺序为(channels, conv_dim1, conv_dim2, conv_dim3)</span><br>    <br>    <span class="hljs-comment">#转换字段类型，并将数据导入变量中</span><br>    X_train = (X_train.astype(np.float32) - <span class="hljs-number">127.5</span>)/<span class="hljs-number">127.5</span><br>    X_train = X_train[:, :, :, <span class="hljs-literal">None</span>]<br>    X_test = X_test[:, :, :, <span class="hljs-literal">None</span>]<br>    <span class="hljs-comment"># X_train = X_train.reshape((X_train.shape, 1) + X_train.shape[1:])</span><br>    <br>    <span class="hljs-comment">#将定义好的模型架构赋值给特定的变量</span><br>    d = discriminator_model()<br>    g = generator_model()<br>    d_on_g = generator_containing_discriminator(g, d)<br>    <br>    <span class="hljs-comment">#定义生成器模型判别器模型更新所使用的优化算法及超参数</span><br>    d_optim = SGD(lr=<span class="hljs-number">0.001</span>, momentum=<span class="hljs-number">0.9</span>, nesterov=<span class="hljs-literal">True</span>)<br>    g_optim = SGD(lr=<span class="hljs-number">0.001</span>, momentum=<span class="hljs-number">0.9</span>, nesterov=<span class="hljs-literal">True</span>)<br>    <br>    <span class="hljs-comment">#编译三个神经网络并设置损失函数和优化算法，其中损失函数都是用的是二元分类交叉熵函数。编译是用来配置模型学习过程的</span><br>    g.<span class="hljs-built_in">compile</span>(loss=<span class="hljs-string">&#x27;binary_crossentropy&#x27;</span>, optimizer=<span class="hljs-string">&quot;SGD&quot;</span>)<br>    d_on_g.<span class="hljs-built_in">compile</span>(loss=<span class="hljs-string">&#x27;binary_crossentropy&#x27;</span>, optimizer=g_optim)<br>    <br>    <span class="hljs-comment">#前一个架构在固定判别器的情况下训练了生成器，所以在训练判别器之前先要设定其为可训练。</span><br>    d.trainable = <span class="hljs-literal">True</span><br>    d.<span class="hljs-built_in">compile</span>(loss=<span class="hljs-string">&#x27;binary_crossentropy&#x27;</span>, optimizer=d_optim)<br>    <br>    <span class="hljs-comment">#下面在满足epoch条件下进行训练</span><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">30</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Epoch is&quot;</span>, epoch)<br>        <br>        <span class="hljs-comment">#计算一个epoch所需要的迭代数量，即训练样本数除批量大小数的值取整；其中shape[0]就是读取矩阵第一维度的长度</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Number of batches&quot;</span>, <span class="hljs-built_in">int</span>(X_train.shape[<span class="hljs-number">0</span>]/BATCH_SIZE))<br>        <br>        <span class="hljs-comment">#在一个epoch内进行迭代训练</span><br>        <span class="hljs-keyword">for</span> index <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">int</span>(X_train.shape[<span class="hljs-number">0</span>]/BATCH_SIZE)):<br>            <br>            <span class="hljs-comment">#随机生成的噪声服从均匀分布，且采样下界为-1、采样上界为1，输出BATCH_SIZE×100个样本；即抽取一个批量的随机样本</span><br>            noise = np.random.uniform(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, size=(BATCH_SIZE, <span class="hljs-number">100</span>))<br>            <br>            <span class="hljs-comment">#抽取一个批量的真实图片</span><br>            image_batch = X_train[index*BATCH_SIZE:(index+<span class="hljs-number">1</span>)*BATCH_SIZE]<br>            <br>            <span class="hljs-comment">#生成的图片使用生成器对随机噪声进行推断；verbose为日志显示，0为不在标准输出流输出日志信息，1为输出进度条记录</span><br>            generated_images = g.predict(noise, verbose=<span class="hljs-number">0</span>)<br>            <br>            <span class="hljs-comment">#每经过100次迭代输出一张生成的图片</span><br>            <span class="hljs-keyword">if</span> index % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>:<br>                image = combine_images(generated_images)<br>                image = image*<span class="hljs-number">127.5</span>+<span class="hljs-number">127.5</span><br>                Image.fromarray(image.astype(np.uint8)).save(<br>                    <span class="hljs-string">&quot;./GAN/&quot;</span>+<span class="hljs-built_in">str</span>(epoch)+<span class="hljs-string">&quot;_&quot;</span>+<span class="hljs-built_in">str</span>(index)+<span class="hljs-string">&quot;.png&quot;</span>)<br>            <br>            <span class="hljs-comment">#将真实的图片和生成的图片以多维数组的形式拼接在一起，真实图片在上，生成图片在下</span><br>            X = np.concatenate((image_batch, generated_images))<br>            <br>            <span class="hljs-comment">#生成图片真假标签，即一个包含两倍批量大小的列表；前一个批量大小都是1，代表真实图片，后一个批量大小都是0，代表伪造图片</span><br>            y = [<span class="hljs-number">1</span>] * BATCH_SIZE + [<span class="hljs-number">0</span>] * BATCH_SIZE<br>            <br>            <span class="hljs-comment">#判别器的损失；在一个batch的数据上进行一次参数更新</span><br>            d_loss = d.train_on_batch(X, y)<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;batch %d d_loss : %f&quot;</span> % (index, d_loss))<br>            <br>            <span class="hljs-comment">#随机生成的噪声服从均匀分布</span><br>            noise = np.random.uniform(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, (BATCH_SIZE, <span class="hljs-number">100</span>))<br>            <br>            <span class="hljs-comment">#固定判别器</span><br>            d.trainable = <span class="hljs-literal">False</span><br>            <br>            <span class="hljs-comment">#计算生成器损失；在一个batch的数据上进行一次参数更新</span><br>            g_loss = d_on_g.train_on_batch(noise, [<span class="hljs-number">1</span>] * BATCH_SIZE)<br>            <br>            <span class="hljs-comment">#令判别器可训练</span><br>            d.trainable = <span class="hljs-literal">True</span><br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;batch %d g_loss : %f&quot;</span> % (index, g_loss))<br>            <br>            <span class="hljs-comment">#每100次迭代保存一次生成器和判别器的权重</span><br>            <span class="hljs-keyword">if</span> index % <span class="hljs-number">100</span> == <span class="hljs-number">9</span>:<br>                g.save_weights(<span class="hljs-string">&#x27;generator&#x27;</span>, <span class="hljs-literal">True</span>)<br>                d.save_weights(<span class="hljs-string">&#x27;discriminator&#x27;</span>, <span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>
<h3 id="程序实例program-example">程序实例（Program Example）</h3>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/hjtso/face-generation/blob/master/dlnd_face_generation.ipynb" title="Title">Github Link</a></li>
</ul>
<h3 id="参考资料reference">参考资料（Reference）</h3>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/30346797" title="Title">生成对抗网络综述：从架构到训练技巧</a></p></li>
<li><p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650731540&amp;idx=1&amp;sn=193457603fe11b89f3d298ac1799b9fd&amp;chksm=871b306ab06cb97c502af9552657b8e73f1f5286bc4cc71b021f64604fd53dae3f026bc9ac69&amp;scene=21#wechat_redirect" title="Title">机器之心GitHub项目：GAN完整理论推导与实现</a></p></li>
<li><p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650730721&amp;idx=2&amp;sn=95b97b80188f507c409f4c72bd0a2767&amp;chksm=871b349fb06cbd891771f72d77563f77986afc9b144f42c8232db44c7c56c1d2bc019458c4e4&amp;scene=21#wechat_redirect" title="Title">深度 | 生成对抗网络初学入门</a></p></li>
<li><p><a target="_blank" rel="noopener" href="https://elix-tech.github.io/ja/2017/02/06/gan.html" title="Title">はじめてのGAN</a></p></li>
</ul>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/Deep-Learning/" class="category-chain-item">Deep Learning</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/Deep-Learning/">#Deep Learning</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Deep learning笔记5-GAN生成式对抗网络</div>
      <div>https://hjtai.github.io/2017/08/20/zh/Deep learning笔记5-GAN生成式对抗网络/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>H.J.T.</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>August 20, 2017</div>
        </div>
      
      
      <div class="license-meta-item">
        <div>Licensed under</div>
        <div>
          
            
            
              <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
              <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                <i class="iconfont icon-by"></i>
              </span>
              </a>
            
          
        </div>
      </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2017/08/25/zh/JUDO-Ono%20Shohei%20%E6%9F%94%E9%81%93-%E5%A4%A7%E9%87%8E%E5%B0%86%E5%B9%B3/" title="JUDO-Ono Shohei 柔道-大野将平">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">JUDO-Ono Shohei 柔道-大野将平</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2017/08/17/zh/Deep%20learning%E7%AC%94%E8%AE%B04-TreeRNN%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="Deep learning笔记4-TreeRNN递归神经网络">
                        <span class="hidden-mobile">Deep learning笔记4-TreeRNN递归神经网络</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;Table of Contents</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hjtai.github.io" target="_blank" rel="nofollow noopener"><span>H.J.T.</span></a> <i class="iconfont icon-love"></i> <a href="https://hjtai.github.io" target="_blank" rel="nofollow noopener"><span>H.J.T.</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.1/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
</body>
</html>
